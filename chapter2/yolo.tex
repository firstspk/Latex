การตรวจจับวัตถุนั้นเป็นหนึ่งในกระบวนการวิเคราะห์ผลของวิดีโอ กล่าวคือกระบวนการที่ผู้วิจัยจะต้องทำการระบุสิ่งที่สนใจว่า คืออะไร อยู่ที่ตำแหน่งใด 	การตรวจจับวัตถุถูกค้นพบเมื่อนานมาแล้ว และในปัจจุบันนั้นสามารถทำได้หลากหลายวิธี โดยภายในบทความนี้จะสรุปใจความสำคัญของวิธีการต่างในการตรวจจับวัตถุ เช่น Sliding Window , Brute Force Search , R-CNN , Fast-RCNN , Faster-RCNN , YOLO , SSD 
\begin{enumerate}
		\item Sliding Window วิธีการที่เปรียบเสมือนมีหน้าต่าง (kernel) ค่อยๆเลื่อนไปยังแต่ละพิกเซลบนรูป ซึ่งก่อนการเลื่อนของหน้าต่างแต่ละครั้ง จะนำส่วนของรูปภาพที่ถูกหน้าต่างทับอยู่ไปทำนายว่าใช่วัตถุที่เราต้องการหรือไม่ จากนั้นจึงค่อยเลื่อนถัดไป โดยจะทำกระบวนการแบบนี้จนครบทั้งรูปภาพ
	\item Brute Force Search ถูกสร้างขึ้นมาเพื่อแก้ปัญหาขนาดของหน้าต่างไม่ตรงกับขนาดของวัตถุที่อยู่ในภาพทำให้มีโอกาสที่จะไม่พบวัตถุ โดยหลักการของวิธีการนี้ คือ การย่อ-ขยาย รูปภาพและนำเข้าในหลายๆอัตราส่วน ตั้งแต่ 0.1 เท่า จนถึง 2 เท่า แต่ข้อเสียของวิธีการนี้คือ มีการคำนวณพื้นที่ซ้ำๆ และ ใช้เวลานาน
	\item R-CNN ใช้อัลกอริทึ่ม Selective search เข้ามาช่วยในการเสนอพื้นที่ที่น่าจะมีวัตถุอยู่ทดแทนการค้นหาทุกๆตำแหน่ง จากนั้นก็นำรูปภาพในส่วนพื้นที่นั้นไปทำนายว่าวัตถุนั้นคืออะไร กรณีที่มีพื้นที่ที่อยู่ใกล้ๆวัตถุถูกเสนอเข้ามาเป็นจำนวนมากด้วย เราจะใช้ Non-Maximum Suppression (NMS) หรือการเลือกพื้นที่ที่ถูกทับซ้อนมากที่สุดในบริเวณนั้น
	\item Fast-RCNN จากวิธีการ R-CNN แต่ละพื้นที่จะถูกนำไปสกัดคุณลักษณะ และ ทำนายผลทีละพื้นที่่ ทำให้เสียเวลา โดย Faster-RCNN จะมีส่วนที่คล้ายกับ R-CNN ในส่วนการทำ Selective search หาพื้นที่ที่น่าจะมีวัตถุเหมือนเดิม แต่ Faster-RCNN จะนำรูปภาพทั้งรูปภาพไปสกัดคุณลักษณะ หลังจากที่ได้คุณลักษณะแล้ว นำพิกัดของพื้นที่ที่น่าจะมีวัตถุ บนรูปภาพที่ถูกสกัดคุณลักษณะแล้วของ ไปผ่าน ROI Pooling (การลดขนาดข้อมูลให้มีขนาดคงที่เพื่อเป็นอินพุทให้กับโมเดลในการทำนายผล)
	\item Faster-RCNN พัฒนาจาก Fast-RCNN โดยวิธีของ Faster-RCNN จะรวมในส่วนของ Selective search และ การทำงานอื่นๆให้อยู่ในโครงข่ายเดียวกัน สรุปคือการทำงานของโครงข่ายของ Faster-RCNN จะมีการทำงาน 3 อย่างหลักคือ 1) สกัดคุณลักษณะ 2) การเสนอส่วนที่น่าจะมีวัตถุอยู่ในรูปภาพ 3) หลังจากได้รูปภาพจากการสกัดคุณลักษณะ นำพิกัดของพื้นที่ที่น่าจะมีวัตถุ บนรูปภาพที่ถูกสกัดคุณลักษณะแล้วของ ไปผ่าน ROI Pooling
	\item YOLO เป็นวิธีการที่ใช้โครงข่ายประสาทแบบคอนโวลูชันเพียงตัวเดียวทำนายรูปภาพทั้งรูป โดยโครงข่ายจะแบ่งรูปภาพออกเป็นพื้นที่ และ ใช้ Fully-connected (เป็นโครงข่ายประสาทเทียมที่นำเอาคุณลักษณะมาทำนายผล) ทำนายตำแหน่งของกรอบสี่เหลี่ยมและหมวดหมู่ของกรอบสี่เหลี่ยมในแต่ละพื้นที่ไปพร้อมกัน 
	\item SSD ใช้โครงข่ายประสาทเทียมตัวเดียวเหมือนกับ YOLO แต่การออกแบบโครงสร้างแตกต่างกัน SSD จะใช้ VGG-16(เป็นโมเดล CNN ชนิดหนึ่ง) ในการสกัดคุณลักษณะ และ ใช้ Convolution layer ต่อกันหลายๆชั้นเพื่อลดมิติและความละเอียดทำให้ตรวจจับวัตถุในหลายๆขนาด ซึ่งในแต่ละชั้นจะได้ผลออกมาเป็น Convolution filter จากนั้นจะนำ Convolution filter ไปทำนายผลต่อ
\end{enumerate}

 



%ซึ่งในปัจจุบันการทำการตรวจจับวัตถุมักนำปัญญาประดิษฐ์มาใช้เนื่องจากมีความแม่นยำ และ ช่วยแบ่งเบาภาระของผู้วิจัยในการระบุสิ่งที่สุดใจภายในเฟรม ซึ่งโครงสร้างโมเดลปัญญาประดิษฐ์ของการตรวจจับวัตถุที่ผู้วิจัยสนใจมีดังนี้
%ข้อมูลผลการทำงานของโมเดลปัญญาประดิษฐ์สำหรับการทำการตรวจจับภาพบุคคล อ้างอิงข้อมูลจากเว็บไซต์ของ YOLO
%\begin{table}[!ht]
%	\begin{tabular}{|c|c|c|}
%		\hline
%		{}&{ความเร็วต่อรูปภาพ (มิลลิวินาที)}&{ความแม่นยำ (0.5 IoU mAP)}			\\
%		\hline
%		SSD Mobilenet v1 ppn	 		& 26				& 20														\\
%		YOLO-v3 320				& 22				& 51.5				\\	
%		YOLO-v3 tiny				& 4.5				& 33.1				\\
%		YOLO-v3 spp				& 50				& 60.6				\\	
%		Faster RCNN inceptrion v2		& 58				& 28		\\
%	\hline
%	\end{tabular}
%	\caption{ข้อมูลผลการทำงานของโมเดลปัญญาประดิษฐ์สำหรับการทำการตรวจจับภาพบุคคล อ้างอิงข้อมูลจากเว็บไซต์ของ YOLO}
%\end{table}


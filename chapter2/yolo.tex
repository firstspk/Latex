การตรวจจับวัตถุนั้นเป็นหนึ่งในกระบวนการประมวผลวิดีโอ\textsuperscript{\cite{object_detection}} กล่าวคือกระบวนการที่ผู้วิจัยจะต้องทำการระบุสิ่งที่สนใจว่า คืออะไร อยู่ที่ตำแหน่งใด การตรวจจับวัตถุถูกค้นพบเมื่อนานมาแล้ว 
และในปัจจุบันนั้นสามารถทำได้หลากหลายวิธี โดยภายในบทความนี้จะสรุปใจความสำคัญของวิธีการต่างในการตรวจจับวัตถุ เช่น Sliding window, Brute force search, RCNN, 
Fast-RCNN, Faster-RCNN, YOLO, SSD 
\begin{enumerate}
	\item Sliding window วิธีการที่เปรียบเสมือนมีเคอร์เนลค่อยๆเลื่อนไปยังแต่ละพิกเซลบนรูป ซึ่งก่อนการเลื่อนของเคอร์เนลแต่ละครั้งจะนำส่วนของภาพที่ถูกเคอร์เนลทับอยู่ไปทำนายว่าใช่วัตถุที่เราต้องการหรือไม่ 
	จากนั้นจึงค่อยเลื่อนถัดไปจนครบทั้งภาพ
	\item Brute force search ถูกสร้างขึ้นมาเพื่อแก้ปัญหาขนาดของเคอร์เนลไม่ตรงกับขนาดของวัตถุที่อยู่ในภาพทำให้มีโอกาสที่จะไม่พบวัตถุ โดยหลักการของวิธีการนี้คือ 
	การย่อ-ขยายภาพและนำเข้าในหลายๆอัตราส่วน ตั้งแต่ 0.1 เท่า จนถึง 2 เท่า แต่ข้อเสียของวิธีการนี้คือ มีการคำนวณพื้นที่ซ้ำๆทำให้ใช้เวลานาน
	\item RCNN ใช้อัลกอริทึ่ม selective search เข้ามาช่วยในการเสนอพื้นที่ที่น่าจะมีวัตถุอยู่ทดแทนการค้นหาทุกๆตำแหน่ง จากนั้นก็นำภาพในส่วนพื้นที่นั้นไปทำนายว่าวัตถุนั้นคืออะไร 
	กรณีที่มีพื้นที่ที่อยู่ใกล้ๆวัตถุถูกเสนอเข้ามาเป็นจำนวนมากด้วย เราจะใช้ NMS ในการเลือกพื้นที่ที่ถูกทับซ้อนมากที่สุดในบริเวณนั้น
	\item Fast-RCNN จากวิธีการ RCNN แต่ละพื้นที่จะถูกนำไปสกัดคุณลักษณะ และทำนายผลทีละพื้นที่่ทำให้เสียเวลา โดย Faster-RCNN จะมีส่วนที่คล้ายกับ RCNN ในส่วนการทำ 
	selective search เพื่อหาพื้นที่ที่น่าจะมีวัตถุเหมือนเดิม แต่ Faster-RCNN จะนำภาพไปสกัดคุณลักษณะ หลังจากที่ได้คุณลักษณะแล้วจะนำพิกัดของพื้นที่ที่น่าจะมีวัตถุ 
	บนภาพที่ถูกสกัดคุณลักษณะแล้วไปผ่านชั้น ROI Pooling (การลดขนาดข้อมูลให้มีขนาดคงที่เพื่อเป็นข้อมูลป้อนเข้าให้กับโมเดลในการทำนายผล)
	\item Faster-RCNN พัฒนาจาก Fast-RCNN โดยวิธีของ Faster-RCNN จะรวมในส่วนของ selective search และการทำงานอื่นๆให้อยู่ในโครงข่ายเดียวกัน 
	สรุปคือการทำงานของโครงข่ายของ Faster-RCNN จะมีการทำงานสามอย่างคือ 1) สกัดคุณลักษณะ 2) การเสนอส่วนที่น่าจะมีวัตถุอยู่ในภาพ 3) หลังจากได้ภาพจากการสกัดคุณลักษณะ 
	นำพิกัดของพื้นที่ที่น่าจะมีวัตถุบนภาพที่ถูกสกัดคุณลักษณะแล้วไปผ่านชั้น ROI Pooling
	\item YOLO เป็นวิธีการที่ใช้ CNN เพียงตัวเดียวทำนายภาพ โดยโครงข่ายจะแบ่งภาพออกเป็นพื้นที่ และใช้ fully connected ทำนายตำแหน่งของกรอบสี่เหลี่ยม 
	พร้อมทั้งหมวดหมู่ของวัตถุไปพร้อมกัน 
	\item SSD ใช้โครงข่ายประสาทเทียมเหมือนกับ YOLO แต่การออกแบบโครงสร้างแตกต่างกัน โดยที่ SSD จะใช้ VGG-16 ในการสกัดคุณลักษณะ และใช้ Convolution layer 
	ต่อกันหลายๆชั้นเพื่อลดมิติและความละเอียดทำให้ตรวจจับวัตถุในหลายๆขนาด ซึ่งในแต่ละชั้นจะได้ผลออกมาเป็น Convolution filter จากนั้นจะนำ Convolution filter ไปทำนายผลต่อ
\end{enumerate}
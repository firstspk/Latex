การตรวจจับวัตถุนั้นเป็นหนึ่งในกระบวนการประมวผลวิดีโอ กล่าวคือกระบวนการที่ผู้วิจัยจะต้องทำการระบุสิ่งที่สนใจว่า คืออะไร อยู่ที่ตำแหน่งใด การตรวจจับวัตถุถูกค้นพบเมื่อนานมาแล้ว 
และในปัจจุบันนั้นสามารถทำได้หลากหลายวิธี โดยภายในบทความนี้จะสรุปใจความสำคัญของวิธีการต่างในการตรวจจับวัตถุ เช่น Sliding Window, Brute Force Search, RCNN, Fast-RCNN, Faster-RCNN, YOLO, SSD 
\begin{enumerate}
	\item Sliding window วิธีการที่เปรียบเสมือนมีเคอร์เนล (kernel) ค่อยๆเลื่อนไปยังแต่ละพิกเซลบนรูป ซึ่งก่อนการเลื่อนของเคอร์เนลแต่ละครั้งจะนำส่วนของรูปภาพที่ถูกเคอร์เนลทับอยู่ไปทำนายว่าใช่วัตถุที่เราต้องการหรือไม่ 
	จากนั้นจึงค่อยเลื่อนถัดไปจนครบทั้งรูปภาพ
	\item Brute force search ถูกสร้างขึ้นมาเพื่อแก้ปัญหาขนาดของเคอร์เนลไม่ตรงกับขนาดของวัตถุที่อยู่ในภาพทำให้มีโอกาสที่จะไม่พบวัตถุ โดยหลักการของวิธีการนี้ คือ การย่อ-ขยาย รูปภาพและนำเข้าในหลายๆอัตราส่วน ตั้งแต่ 0.1 เท่า จนถึง 2 เท่า แต่ข้อเสียของวิธีการนี้คือ มีการคำนวณพื้นที่ซ้ำๆ และ ใช้เวลานาน
	\item RCNN ใช้อัลกอริทึ่ม selective search เข้ามาช่วยในการเสนอพื้นที่ที่น่าจะมีวัตถุอยู่ทดแทนการค้นหาทุกๆตำแหน่ง จากนั้นก็นำรูปภาพในส่วนพื้นที่นั้นไปทำนายว่าวัตถุนั้นคืออะไร กรณีที่มีพื้นที่ที่อยู่ใกล้ๆวัตถุถูกเสนอเข้ามาเป็นจำนวนมากด้วย เราจะใช้ Non-Maximum Suppression (NMS) หรือการเลือกพื้นที่ที่ถูกทับซ้อนมากที่สุดในบริเวณนั้น
	\item Fast-RCNN จากวิธีการ RCNN แต่ละพื้นที่จะถูกนำไปสกัดคุณลักษณะ และ ทำนายผลทีละพื้นที่่ ทำให้เสียเวลา โดย Faster-RCNN จะมีส่วนที่คล้ายกับ RCNN ในส่วนการทำ selective search หาพื้นที่ที่น่าจะมีวัตถุเหมือนเดิม แต่ Faster-RCNN จะนำรูปภาพทั้งรูปภาพไปสกัดคุณลักษณะ หลังจากที่ได้คุณลักษณะแล้ว นำพิกัดของพื้นที่ที่น่าจะมีวัตถุ บนรูปภาพที่ถูกสกัดคุณลักษณะแล้วของ ไปผ่าน ROI Pooling (การลดขนาดข้อมูลให้มีขนาดคงที่เพื่อเป็นอินพุทให้กับโมเดลในการทำนายผล)
	\item Faster-RCNN พัฒนาจาก Fast-RCNN โดยวิธีของ Faster-RCNN จะรวมในส่วนของ selective search และ การทำงานอื่นๆให้อยู่ในโครงข่ายเดียวกัน สรุปคือการทำงานของโครงข่ายของ Faster-RCNN จะมีการทำงาน 3 อย่างหลักคือ 1) สกัดคุณลักษณะ 2) การเสนอส่วนที่น่าจะมีวัตถุอยู่ในรูปภาพ 3) หลังจากได้รูปภาพจากการสกัดคุณลักษณะ นำพิกัดของพื้นที่ที่น่าจะมีวัตถุ บนรูปภาพที่ถูกสกัดคุณลักษณะแล้วของ ไปผ่าน ROI Pooling
	\item YOLO เป็นวิธีการที่ใช้โครงข่ายประสาทแบบคอนโวลูชั่นเพียงตัวเดียวทำนายรูปภาพทั้งรูป โดยโครงข่ายจะแบ่งรูปภาพออกเป็นพื้นที่ และ ใช้ fully-connected (เป็นโครงข่ายประสาทเทียมที่นำเอาคุณลักษณะมาทำนายผล) ทำนายตำแหน่งของกรอบสี่เหลี่ยมและหมวดหมู่ของกรอบสี่เหลี่ยมในแต่ละพื้นที่ไปพร้อมกัน 
	\item SSD ใช้โครงข่ายประสาทเทียมตัวเดียวเหมือนกับ YOLO แต่การออกแบบโครงสร้างแตกต่างกัน SSD จะใช้ VGG-16 (เป็นโมเดล CNN ชนิดหนึ่ง) ในการสกัดคุณลักษณะ และ ใช้ Convolution layer ต่อกันหลายๆชั้นเพื่อลดมิติและความละเอียดทำให้ตรวจจับวัตถุในหลายๆขนาด ซึ่งในแต่ละชั้นจะได้ผลออกมาเป็น Convolution filter จากนั้นจะนำ Convolution filter ไปทำนายผลต่อ
\end{enumerate}
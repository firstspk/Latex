ในส่วนของงานวิจัยสิ่งที่เราให้ความสนใจ คือ ข้อมูลการกระทำของมนุษย์แต่ละคนภายในวิดีโอ  ซึ่งเพื่อที่เราจะได้ผลลัพธ์ที่มีประสิทธิภาพออกมาเป็นข้อมูลของสิ่งที่เราสนใจและสามารถนำไปใช้ต่อได้ เราจึงจำเป็นจะต้องใช้การวิเคราะห์ผลวิดีโอเพื่อที่จะสกัดสิ่งที่เราสนใจออกมาจากวิด๊โอ ซึ่งการวิเคราะห์ผลวิดีโอมีหลากหลายกระบวนการในการทำ จะทำทีละขั้นตอน โดยในแต่ละกระบวนการจะมีจุดประสงค์ของการทำและผลลัพธ์หลังการทำที่แตกต่างกัน ในหัวข้อนี้จะมาอธิบายถึงกระบวนการในการวิเคราะห์ผลของวิดิโอและผลลัพธ์ของการทำกระบวนการนั้น

\subsubsection*{2.1.1 การตรวจจับวัตถุ}
การตรวจจับวัตถุเป็นสิ่งที่สำคัญเป็นอันดับต้นๆของการวิเคราะห์ผลของวิดีโอ คือ การตรวจจับวัตถุ กล่าวคือกระบวนการที่ผู้วิจัยจะต้องทำคือระบุสิ่งที่สนใจว่าคืออะไร อยู่ตำแหน่งใด ซึ่งในปัจจุบันการทำการตรวจจับวัตถุมักนำ Machine learning model มาใช้เพื่อช่วยตรวจจับวัตถุที่เราสนใจ ซึ่ง Machine learning model ที่เราเลือกใช้คือ YOLO v3 โดยเหตุผลที่เราเลือกใช้ Machine learning model YOLO v3 จะถูกกล่าวไว้อยู่ในหัวข้อ Machine learning model ในหัวข้อถัดไป
\clearpage
\par
YOLO v3 เป็น Machine learning model ที่ในปัจจุบันนิยมนำมาใช้ตรวจจับวัตถุในงานวิเคราะห์ผลของวิดีโอ เนื่องจากสามารถตรวจจับวัตถุได้แบบเรียลไทม์และมีความแม่นยำ โดยหลักการของ YOLO v3 คือ นำรูปภาพที่ต้องการตรวจจับตำแหน่งของวัตถุผ่าน neural network โดยโครงข่ายจะแบ่งรูปภาพเป็นพื้นที่ และ จะทำนายกรอบสี่เหลี่ยมพร้อมกับทำนายความน่าจะเป็นของแต่ละหมวดหมู่ในแต่ละพื้นที่ สุดท้ายจะเลือกกรอบสี่เหลี่ยมและหมวดหมู่ที่มีค่าคะแนนความน่าจะเป็นมากที่สุด

\subsubsection*{2.1.2 การทำนายตำแหน่งถัดไปของวัตถุ (Tracking)}
\input{chapter2/tracking}

\subsubsection*{2.1.3 การระบุตัวตนของบุคคล (ReID)}
\input{chapter2/reid}

\subsubsection*{2.1.4 การจดจำการกระทำ}
\input{chapter2/action_label}